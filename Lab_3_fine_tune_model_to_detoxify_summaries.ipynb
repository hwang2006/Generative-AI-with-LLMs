{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27946de2-409b-4c21-a27b-0d384ba0ea83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/lvwerra/trl.git@25fa1bd\n",
      "  Cloning https://github.com/lvwerra/trl.git (to revision 25fa1bd) to /tmp/pip-req-build-qq003cvl\n",
      "  Running command git clone --quiet https://github.com/lvwerra/trl.git /tmp/pip-req-build-qq003cvl\n",
      "\u001b[33m  WARNING: Did not find branch or tag '25fa1bd', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 25fa1bd\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit 25fa1bd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from trl==0.4.2.dev0) (2.0.1)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from trl==0.4.2.dev0) (4.36.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from trl==0.4.2.dev0) (1.26.2)\n",
      "Requirement already satisfied: accelerate in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from trl==0.4.2.dev0) (0.25.0)\n",
      "Requirement already satisfied: datasets in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from trl==0.4.2.dev0) (2.15.0)\n",
      "Requirement already satisfied: filelock in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl==0.4.2.dev0) (68.2.2)\n",
      "Requirement already satisfied: wheel in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl==0.4.2.dev0) (0.41.2)\n",
      "Requirement already satisfied: cmake in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->trl==0.4.2.dev0) (3.28.1)\n",
      "Requirement already satisfied: lit in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->trl==0.4.2.dev0) (17.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (4.66.1)\n",
      "Requirement already satisfied: psutil in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from accelerate->trl==0.4.2.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->trl==0.4.2.dev0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (3.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.4.2.dev0) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.4.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.2.dev0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/lvwerra/trl.git@25fa1bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ca6dfb-36f0-4f0a-890a-c2fc76afeb48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c168144a-6025-4216-b0fc-14274b0d3342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"google/flan-t5-base\"\n",
    "#model_name=\"google/flan-t5-large\"\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e382d5-d5ee-4ce5-9d0f-f8e60112b350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(model_name,\n",
    "                  dataset_name,\n",
    "                  input_min_text_length, \n",
    "                  input_max_text_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name.\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "        \n",
    "    Returns:\n",
    "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load dataset (only \"train\" part will be enough for this lab).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        \n",
    "        # Wrap each dialogue with the instruction.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        \n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue.\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # Split the dataset into train and test parts.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200, \n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48a6d27-819e-4e1b-b175-846fb2bf7912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245eda07-3c0d-4352-9bd5-c5a8e945e53b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, \n",
    "                                       './peft-dialogue-summary-checkpoint-local/', \n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16, \n",
    "                                       device_map=\"auto\",                                       \n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ccb560-922d-41ad-aa82-573cccb611c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 3539713\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65df4385-e49a-4ff9-a7dd-c84392372816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 0\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7205fa7-48a8-4e3a-b09f-a10d0758c22e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13e5b6ad-6f49-4b84-9de7-35d729804086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.114102840423584, -2.489619255065918]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.003670602338388562]\n",
      "reward (high): [3.114102840423584]\n"
     ]
    }
   ],
   "source": [
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "#logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids.to(\"cuda\")).logits\n",
    "\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b02d32cd-3930-4240-b2a3-abbf77b43970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.114102840423584, -2.489619255065918]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.003670602338388562]\n",
      "reward (high): [3.114102840423584]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "toxicity_input_ids = toxicity_input_ids.to(device)\n",
    "\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb1b81cb-dece-461e-894d-2bd11a0c9717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [-0.692115306854248, 0.37226977944374084]\n",
      "probabilities [not hate, hate]: [0.25647231936454773, 0.7435276508331299]\n",
      "reward (low): [-0.692115306854248]\n"
     ]
    }
   ],
   "source": [
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
    "toxicity_input_ids = toxicity_input_ids.to(device)\n",
    "\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# Get the logits for \"not hate\" - this is the reward!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist() \n",
    "print(f'reward (low): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48e84e1-0866-4f57-aa89-2c50efd27911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text\n",
      "[{'label': 'nothate', 'score': 3.114102840423584}, {'label': 'hate', 'score': -2.489619255065918}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.003670602571219206}]\n",
      "For toxic text\n",
      "[{'label': 'hate', 'score': 0.37226977944374084}, {'label': 'nothate', 'score': -0.692115306854248}]\n",
      "[{'label': 'hate', 'score': 0.7435276508331299}, {'label': 'nothate', 'score': 0.2564723491668701}]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \n",
    "                          model=toxicity_model_name, \n",
    "                          device=device)\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"For toxic text\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992e3f38-08e6-450c-9537-a8d928c8c720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 3.114102840423584}, {'label': 'hate', 'score': -2.489619255065918}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.003670602571219206}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f4316f-7dee-4131-89ef-763b5b1b508e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'hate', 'score': 0.37226977944374084}, {'label': 'nothate', 'score': -0.692115306854248}]\n",
      "[{'label': 'hate', 'score': 0.7435276508331299}, {'label': 'nothate', 'score': 0.2564723491668701}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de55b02d-72ff-4e39-b3d0-c3ad5eb52a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 4.620528697967529}, {'label': 'hate', 'score': -4.193256378173828}]\n",
      "[{'label': 'nothate', 'score': 0.9998513460159302}, {'label': 'hate', 'score': 0.0001486473047407344}]\n"
     ]
    }
   ],
   "source": [
    "text = \"I love you.\"\n",
    "print(sentiment_pipe(text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1173ae37-8fd0-468a-a384-d9d1d37fba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 4.629112720489502}, {'label': 'hate', 'score': -4.079700946807861}]\n",
      "[{'label': 'nothate', 'score': 0.9998348951339722}, {'label': 'hate', 'score': 0.00016509677516296506}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text = \"How are you doing today?\"\n",
    "print(sentiment_pipe(text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ad34aa-74e4-4f99-b3fa-ed77bcc418bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'hate', 'score': 0.9263184070587158}, {'label': 'nothate', 'score': -1.2262401580810547}]\n",
      "[{'label': 'hate', 'score': 0.8959076404571533}, {'label': 'nothate', 'score': 0.10409237444400787}]\n"
     ]
    }
   ],
   "source": [
    "text = \"#Person 1# tells Tommy that he was terrible, dumb and stupid.\"\n",
    "print(sentiment_pipe(text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99b8e51-c9fc-4178-b41b-bdbbf1b1913f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxicity_evaluator = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "515c7b1c-d0e5-43ba-a6ae-1fc6b1d1a35e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text:\n",
      "[0.003670593723654747]\n",
      "\n",
      "Toxicity score for toxic text:\n",
      "[0.7435286641120911]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for non-toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\nToxicity score for toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a74e8da-4af8-4f79-9b1c-b1b0d3ff9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for text:\n",
      "[0.8959075212478638]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad62660-c829-4971-9a46-8103eaaf2abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model, \n",
    "                      toxicity_evaluator, \n",
    "                      tokenizer, \n",
    "                      dataset, \n",
    "                      num_samples):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model (trl model): Model to be evaluated.\n",
    "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
    "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
    "    - dataset (dataset): Input dataset for the evaluation.\n",
    "    - num_samples (int): Maximum number of samples for the evaluation.\n",
    "        \n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy.float64 values:\n",
    "    - mean (numpy.float64): Mean of the samples toxicity.\n",
    "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "            \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        \n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids.to(\"cuda\"),\n",
    "                                            generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    # Compute mean & std using np.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "        \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0450ed5-401e-4d9e-909e-3593b5be0dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: So then I can't use my phone if I'm on the internet? #Person2#: That's correct. With DEL you can do both. Summary: </s>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"test\"][0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf69d4a0-7bd6-4b20-bc53-7a97079e527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# wants to order some Dial-up DEL. #Person2# says Dial-up doesn't tie up the phone, it's a phone line.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "input_text = dataset[\"test\"][0][\"query\"]\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        \n",
    "generation_config = GenerationConfig(max_new_tokens=100,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "print(tokenizer.decode(response_token_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9ac6bd6-fc84-462a-a515-f7c9c0438777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# would like to buy DEL mainly for the purpose of internet access. When you download, the dial-up won't tie up the phone because it doesn't have the battery.\n"
     ]
    }
   ],
   "source": [
    "input_text = dataset[\"test\"][0][\"query\"]\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        \n",
    "generation_config = GenerationConfig(max_new_tokens=100,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "response_token_ids = ref_model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "print(tokenizer.decode(response_token_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "daf4a795-90a2-4166-a102-52f9816b02a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1# wants to buy DEL internet. #Person2# recommends Dial-up. DEL is connected through your phone line so people won't have to call for the phone. Dial-up is a good option.\n"
     ]
    }
   ],
   "source": [
    "input_text = dataset[\"test\"][0][\"query\"]\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        \n",
    "generation_config = GenerationConfig(max_new_tokens=100,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "response_token_ids = peft_model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "print(tokenizer.decode(response_token_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cde5e14-6441-4102-b770-c31a8f861284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:08,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] before detox: [0.029523820589846848, 0.034844270097893086]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "ref_model = ref_model.to(\"cuda\")\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model, \n",
    "                                                                          toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                          tokenizer=tokenizer, \n",
    "                                                                          dataset=dataset[\"test\"], \n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64db59f0-1e94-417f-9a76-0952676bd1be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63dae61c-6b40-4b15-9ca4-74e3e32c5d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,    \n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config, \n",
    "                         model=ppo_model, \n",
    "                         ref_model=ref_model, \n",
    "                         tokenizer=tokenizer, \n",
    "                         dataset=dataset[\"train\"], \n",
    "                         data_collator=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd78ec8-5e07-48bc-b925-22d4074920b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "1it [00:13, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 18.309917449951172\n",
      "ppo/returns/mean: -0.13638968765735626\n",
      "ppo/policy/advantages_mean: -7.314961969484557e-10\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:26, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 15.68906307220459\n",
      "ppo/returns/mean: 0.16646350920200348\n",
      "ppo/policy/advantages_mean: -3.769155654254064e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:41, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 19.725345611572266\n",
      "ppo/returns/mean: -0.07756705582141876\n",
      "ppo/policy/advantages_mean: 1.3074423321768336e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:55, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.192190170288086\n",
      "ppo/returns/mean: -0.20222367346286774\n",
      "ppo/policy/advantages_mean: 1.0820319751303487e-08\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:10, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 20.02402114868164\n",
      "ppo/returns/mean: -0.24111312627792358\n",
      "ppo/policy/advantages_mean: 3.291474648392523e-09\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [01:25, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 21.952360153198242\n",
      "ppo/returns/mean: -0.2910740077495575\n",
      "ppo/policy/advantages_mean: -7.242597632739489e-10\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps.\n",
    "    if step >= max_ppo_steps:\n",
    "        break   \n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "    #prompt_tensors = prompt_tensors.to(device)\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()        \n",
    "            \n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]    \n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee508bd-cfb1-4269-8a80-815500733869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ppo_model = ppo_model.to(\"cpu\")\n",
    "ppo_model = ppo_model.to(\"cuda\")\n",
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model, \n",
    "                                                                        toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                        tokenizer=tokenizer, \n",
    "                                                                        dataset=dataset[\"test\"],\n",
    "                                                                        #dataset=dataset[\"test\"].to(device),\n",
    "                                                                        num_samples=10)\n",
    "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dec2a8-898f-4bdc-87d7-44a38b6fae9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'Percentage improvement of toxicity score after detoxification:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d00433-74f0-4bbe-bc76-0ecf22d33e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppo_model = ppo_model.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    \n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb96c16-6fb8-4bdd-8407-ca6641f29fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf8a82-1a32-4c41-88e5-9622573a6ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
